<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Some Key Publications of NICS-EFC Lab]]></title>
    <url>%2F2019%2F03%2F19%2FSome-Key-Publications-of-NICS-EFC-Lab%2F</url>
    <content type="text"><![CDATA[[CNN Accelerator on FPGA, FGPA 2016] Going Deeper with Embedded FPGA Platform for Convolutional Neural Network. [LSTM Accelerator on FPGA, FGPA 2017 Best Paper] ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA. [FPGA in the Cloud, CF 2014] Enabling FPGAs in the Cloud. [MapReduce on FPGA, FPGA 2010] FPMR: MapReduce Framework on FPGA A Case Study of RankBoost Acceleration. [PIM with ReRAM, ISCA 2016] PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory. 1. Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J. Tang, T., Xu, N., Song, S., Wang, Yu (2016): Going Deeper with Embedded FPGA Platform for Convolutional Neural Network. Accepted in: The 24th ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA’16).The CNN-based approach has achieved great success in many applications, however, the computational-intensive and resource-consuming nature of CNN makes it difficult to run CNN on embedded systems. In this paper, we make an in-depth investigation of the memory footprint and bandwidth problem in order to accelerate state-of-the-art CNN models for Imagenet classification on the embedded FPGA platform and show that CONV layers are computational-centric and Fully-Connected layers are memory-centric. In addition, a dynamic-precision data quantization method and a convolver design that is efficient for all layer types in CNN are proposed to improve the bandwidth and resource utilization. A data arrangement method for FC layers is proposed to further ensure a high utilization of the external memory bandwidth. Empirical experiments have shown that the proposed method is very efficient, so CNN can run at high speed on the embedded platform without significantly reducing the accuracy. The analysis in this work makes key inspiration for the subsequent FPGA-based CNN accelerators. 2. Han, S., Kang, J., Mao, H., Hu, Y., Li, X., Li, Y, Xie, D., Luo, H., Yao, S., Wang, Yu, Yang, H., Dally, W. J. (2017): ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA. Accepted in: The 25th ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA’17).Increasingly large LSTM models are used to improve the accuracy of speech recognition tasks, which is both computation and memory intensive and leads to high power consumption. In this paper, we propose a method to compress the LSTM model by $20\times$ with high hardware utilization while without sacrificing the prediction accuracy. Then we propose a scheduler that encodes and partitions the compressed model to multiple PEs for parallelism and schedules the complicated LSTM data flow. And a hardware architecture, named ESE, is designed to deals with the irregularity caused by compression, so that it can work directly on the sparse LSTM model. Experiments show that LSTM implemented on Xilinx FPGAs with ESE is superior to LSTM on top-level CPUs and GPUs, and has higher energy efficiency. This work allows us to not only accelerate CNN on the FPGA, but also accelerate LSTM, giving our FPGA-based accelerators a wider range of applications and higher scalability potential. 3. Chen, F., Shan, Y., Zhang, Y., Wang, Yu, Franke, H., Chang, X., Wang, K. (2014): Enabling FPGAs in the Cloud. Accepted in: Proceedings of the 11th ACM Conference on Computing Frontiers (CF’14).Cloud computing is becoming a major trend for delivering and accessing infrastructure on demand via the network. Many types of workloads in the cloud can be accelerated by FPGAs, as FPGAs have the ability to achieve high throughput and predictable latency while providing programmability, low power consumption and time-to-value. However, integrating FPGAs into the cloud is nontrivial due to some FPGA-related issues. In this paper, we analyze the impediments to bringing FPGAs as a shareable resource to the cloud. To overcome these impediments, we provide a framework and a prototype to provide an FPGA cloud solution within the scope of FPGA technology at the time. The prototype enables isolation between multiple processes in multiple VMs, precise quantitative acceleration resource allocation, and priority-based workload scheduling. Given the prototype, we also demonstrate how abstraction, sharing, compatibility and security can be achieved while using FPGAs in the cloud. This work provides a viable solution to use FPGAs for computational acceleration in the cloud. 4. Shan, Y., Wang, B., Yan, J., Wang, Yu, Xu, N., Yang, H. (2010): FPMR: MapReduce Framework on FPGA A Case Study of RankBoost Acceleration. Accepted in: The 18th ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA’10).FPGA provides a highly parallel, low power, and flexible hardware platform for machine learning and data mining, while the difficulty of programming FPGA greatly limits its prevalence. MapReduce is a parallel programming framework that could easily utilize inherent parallelism in algorithms. In this paper, we propose a MapReduce framework on FPGA, called FPMR, which provides programming abstraction, hardware architecture and basic building blocks to developers. High Parallelism can be easily achieved on FPMR, while the programming efforts are alleviated. Using this framework, designers only need to map the applications onto the mapper modules and the reducer modules. Task scheduling, communication, and data synchronization are done by the framework automatically. In addition, we discuss the tradeoffs among resources, performance, and memory bandwidth, and show that the bandwidth of memory will be the limiting factor during the application acceleration based on FPMR. This work can help developers to build and test machine learning accelerators on FPGAs faster, which is beneficial to the development of the community. 5. Chi, P., Li, S., Xu, C., Zhang, T., Zhao, J., Liu, Y., Wang, Yu, Xie, Y. (2016): PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory. Accepted in: The 43rd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA’16).Processing-in-memory (PIM) is a promising solution to address the “memory wall” challenges for future computer systems. Instead of putting additional computation logic in or near memory, we propose a novel PIM architecture, called PRIME, to accelerate NN applications in ReRAM-based main memory, where ReRAM is an emerging metal-oxide resistive random access memory. In PRIME, a portion of ReRAM crossbar arrays can be configured as accelerators for NN applications or as normal memory for a larger memory space, which takes advantage of both the PIM architecture and the efficiency of ReRAM-based computation. Then we present our designs from circuit-level to system-level and take experiments to demonstrate the ability of the proposed architecture to save energy and accelerate various NN applications using MLP and CNN. This work uses the PIM architecture to reduce memory limitations while speeding up NN applications, providing a new type of accelerator structure.]]></content>
      <categories>
        <category>paper-reading</category>
        <category>survey</category>
      </categories>
      <tags>
        <tag>NICS</tag>
        <tag>FPGA</tag>
        <tag>NN-accelerator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Monocular Visual-Odometry SLAM System]]></title>
    <url>%2F2019%2F03%2F18%2FMonocular-Visual-Odometry-SLAM-System%2F</url>
    <content type="text"><![CDATA[[In Chinese]Notes about some feature-based and NN-based Visual-Inertial Odometry Systems: On-Manifold Preintegration for Real-Time Visual-Inertial Odometry. (IEEE Trans. on Robotics) VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator. (IEEE Trans. on Robotics) Online Temporal Calibration for Monocular Visual-Inertial Systems. (IROS 2018) VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problem. (AAAI 2017) Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correction. (IROS 2018) Selective Sensor Fusion for Neural Visual-Inertial Odometry. (CVPR 2019)]]></content>
      <categories>
        <category>paper-reading</category>
        <category>in Chinese</category>
        <category>survey</category>
      </categories>
      <tags>
        <tag>VIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cardiopulmonary resuscitation (CPR)]]></title>
    <url>%2F2019%2F03%2F16%2FCardiopulmonary-resuscitation-CPR%2F</url>
    <content type="text"><![CDATA[[In Chinese]In case of emergency, how to maintain the life of the patient without breathing and heartbeat and wait for rescue ? 心肺复苏（CPR） 确认患者三无（无意识，无呼吸，无心跳）之后： 大声呼唤，寻求帮助（“快来人，这里有人需要急救”） 说明身份，建立初步信任（“我学过急救知识，我是救护员”） 找人拨打急救电话，并询问结果，判断是否需要派人去接应急救人员（“麻烦您去拨打急救电话，并把结果告诉我”） 寻求另一救护员帮助（“有谁学过急救，过来帮下忙”） 取回AED（“附近有AED的话麻烦拿过来”） 心肺复苏后，发现呼吸心跳恢复，将患者衣物恢复，转成侧卧位，避免窒息 心脏不适如果有人心脏不适，询问情况后，协助其服用随身药物 速效救心丸：正常情况3-5粒，紧急情况10-15粒，舌下含服 硝酸甘油：一次一片，如果无效的话五分钟后再服一片，最多使用三片 中风 没有特定药物 让患者举手，学话，说“一”/微笑，观察肌肉是否正常，如果不正常，大概率是颅脑出现问题，可作初步诊断提供给后续救治的医生 呼吸道异物阻塞]]></content>
      <categories>
        <category>skills</category>
        <category>in Chinese</category>
      </categories>
      <tags>
        <tag>CPR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Two NN-based VIO Methods]]></title>
    <url>%2F2019%2F03%2F13%2FTwo-NN-based-VIO-Methods%2F</url>
    <content type="text"><![CDATA[[In Chinese]Notes about two NN-based VIO methods:1) VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problem2) Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correction VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problemhttps://arxiv.org/pdf/1701.08376.pdf 主要贡献 第一个端到端训练的VIO系统，把VIO看做是Seq2Seq的回归问题 利用RNN（LSTM）提取序列中的时序变化关系，先通过CNN提取图像的特征，然后与LSTM提取的IMU特征拼接起来，再通过另一个LSTM输出最终的pose，通过两个LSTM解决了IMU的频率高于相机频率的问题，即利用LSTM实现了类似pre-integration的作用 其实就是利用RNN避免了复杂的动力学建模 提出了一个新的可微的位姿concat层，它允许网络的预测符合SE(3)流形的结构（输出更易得到的se(3)，然后通过exp层得到SE(3)） 网络结构网络输入单目相机的前后两帧RGB图像，和6D的IMU数据（3D加速度和3D角速度），网络输出为7D的矢量（3D的位移矢量和表示旋转的四元数） 实现细节 使用两层的LSTM，含有1000个cell 在前向时CNN部分消耗了160ms($\approx10Hz$)左右的时间，而LSTM部分可以超过200Hz，都是在Tesla k80上测得的结果 分别使用se(3)和SE(3)计算了loss，在训练初期SE(3)的loss比重小，后期增大 存在的问题 论文中对于精度的说明不太多，对比的也不是目前精度最好的结果 仍然需要相机和IMU之间的外部标定参数，而且是有监督的训练（这个评价来自下面的Vision-Aided ATE）# 标定参数是怎么用到的我还没有发现，可以在之后尝试的时候关注一下… Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correctionhttps://arxiv.org/pdf/1803.05850.pdf 主要贡献 提出了一种在线纠错的方法，可以提高模型的鲁棒性 不需要使用IMU的内参和与相机之间标定的外参 松散的相机和IMU的时间同步 使用无监督训练框架实现VIO系统 网络结构 Overview Details通过CNN先对输入的IMU数据进行处理，先输出对pose的粗略估计，然后与source RGB-D image和source coordinates通过STN进行图像重建，将重建误差求Jacobian，然后再将Jacobian输入到下一个level，实现增量估计，逐个level传递后，使用每个level的位姿估计中重建误差最小的位姿作为最后的输出，在inference时也输出多个尺寸，然后取其最优，即所谓的online correction. 实验结果基本除了比ORB-SLAM2要差，和其他方法比还是有优势的，不过没有和VINS系统的对比结果 存在的问题 使用RGB-D作为输入，可以考虑使用SfM的方法，通过网络预测深度图，从而实现基于纯单目RGB相机的VIO 前向时输出多个尺寸，相当于增加了几倍的计算量，论文中没有给出时间的结果，感觉不能做的很快 IMU本身就能推出一个粗略的位姿，使用CNN处理IMU数据是不是合适？可以之后尝试一下（#TODO） 对比及思考 两篇文章都没有使用复杂的动力学建模，而是分别使用LSTM和CNN“简化”了IMU数据的处理过程，目前看效果也还可以，不过IMU本身可以推断出两个自由度的位姿（pitch&amp;roll），利用数学建模和深度网络结合是不是会更稳妥？ 使用无监督估计深度和位姿，然后将深度图与输入的RGB图放在一起即可使用原本基于RGB-D图像的方法，之后可以多看看这方面的东西 对于多机mapping，如果基于深度图建图，能不能利用深度预测网络的bottleneck特征作为传输数据，然后在接收后decoder，也许还能对特征进一步压缩，或许可行？ 直觉上看，LSTM应该更适合这种基于视频帧的任务，可以主要尝试一下]]></content>
      <categories>
        <category>paper-reading</category>
        <category>in Chinese</category>
      </categories>
      <tags>
        <tag>VIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>blog-building</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
